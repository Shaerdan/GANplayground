{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transforms to be applied to the images\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()] # Normalize with mean and std\n",
    ")\n",
    "\n",
    "# Load the training dataset\n",
    "batch_size = 32\n",
    "trainset = datasets.CIFAR100(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "# Create a data loader for the training dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "# Get one or two images from the training set\n",
    "image, label = trainset[0]\n",
    "print(image.shape)\n",
    "image = image.permute(1, 2, 0)\n",
    "\n",
    "# Visualize the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Label: {}'.format(label))\n",
    "plt.show()\n",
    "        \n",
    "image_size_x = 32\n",
    "image_size_y = 32 \n",
    "num_channels = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_datasize = image_size_x*image_size_y*num_channels # a sample in the trainset is a square image of 32*32, and 3 color channels.\n",
    "input_noise_size = 100;\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Downsample layers\n",
    "        self.conv1 = DoubleConv(in_channels, 24)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = DoubleConv(24, 48)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = DoubleConv(48, 96)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = DoubleConv(96, 192)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Upsample layers\n",
    "        self.up5 = nn.ConvTranspose2d(192, 96, kernel_size=2, stride=2)\n",
    "        self.conv5 = DoubleConv(192, 96)\n",
    "        self.up6 = nn.ConvTranspose2d(96, 48, kernel_size=2, stride=2)\n",
    "        self.conv6 = DoubleConv(96, 48)\n",
    "        self.up7 = nn.ConvTranspose2d(48, 24, kernel_size=2, stride=2)\n",
    "        self.conv7 = DoubleConv(48, 24)\n",
    "        \n",
    "        # Output layer\n",
    "        self.out = nn.Conv2d(24, in_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Downsample\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.pool1(x1)\n",
    "        #print(f\"x2 is {x2.shape}\")\n",
    "        x2 = self.conv2(x2)\n",
    "        x3 = self.pool2(x2)\n",
    "        x3 = self.conv3(x3)\n",
    "        x4 = self.pool3(x3)\n",
    "        x4 = self.conv4(x4)  \n",
    "        #print(f\"x4 is {x4.shape}\")\n",
    "              \n",
    "        # Upsample\n",
    "        x5 = self.up5(x4)\n",
    "        #print(f\"x5 is {x5.shape}\")\n",
    "        #print(f\"x3 is {x3.shape}\")        \n",
    "        x5 = torch.cat([x5, x3], dim=1)\n",
    "        x5 = self.conv5(x5)\n",
    "        x6 = self.up6(x5)\n",
    "        x6 = torch.cat([x6, x2], dim=1)\n",
    "        x6 = self.conv6(x6)\n",
    "        x7 = self.up7(x6)\n",
    "        x7 = torch.cat([x7, x1], dim=1)\n",
    "        x7 = self.conv7(x7)\n",
    "        \n",
    "        # Output\n",
    "        out = self.out(x7)\n",
    "        return out\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channels, 32, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 2, 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 2, 1)\n",
    "        self.conv5 = nn.Conv2d(256, 512, 3, 2, 1)\n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.lrelu(x)\n",
    "        #print(f\"output of conv5 and lrelu is {x.shape}\")\n",
    "        x = x.view(-1, 512 * 2 * 2)\n",
    "        #print(f\"input of fc1 after view is {x.shape}\")        \n",
    "        x = self.fc1(x)\n",
    "        x = self.lrelu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "#criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Define the optimizers\n",
    "lr_dis = 0.0002\n",
    "lr_gen = 0.00008\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "\n",
    "# define the models:\n",
    "generator = UNet().to(device)\n",
    "discriminator = Discriminator(num_channels=3).to(device)\n",
    "\n",
    "# Define the loss function and optimizer for the discriminator\n",
    "criterion_D = nn.BCELoss()\n",
    "\n",
    "# Define the loss function and optimizer for the generator\n",
    "criterion_G = nn.BCELoss()\n",
    "\n",
    "# Create the generator optimizer\n",
    "optimizer_G = torch.optim.SGD(generator.parameters(), lr=lr_gen)\n",
    "\n",
    "# Create the discriminator optimizer\n",
    "optimizer_D = torch.optim.SGD(discriminator.parameters(), lr=lr_dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "print(\"debug chk\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(trainloader):\n",
    "        # Train the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        real_images = images.to(device)\n",
    "        #print(f\"size of real_images is {real_images.shape}\")        \n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        noise_input_D = torch.randn(batch_size, 3, 32,32).to(device)\n",
    "        fake_images = generator(noise_input_D).detach()\n",
    "        #print(f\"size of fake_images is {fake_images.shape}\")\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "        inputchk = discriminator(real_images)\n",
    "        #print(inputchk.shape)\n",
    "        discriminator_loss_real = criterion_D(discriminator(real_images), real_labels)\n",
    "        discriminator_loss_fake = criterion_D(discriminator(fake_images), fake_labels)\n",
    "        discriminator_loss = discriminator_loss_real + discriminator_loss_fake\n",
    "        discriminator_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Train the generator\n",
    "        generator.zero_grad()\n",
    "        noise_input_G = torch.randn(batch_size, 3, 32,32).to(device)        \n",
    "        fake_images = generator(noise_input_G)\n",
    "        generator_loss = criterion_G(discriminator(fake_images), real_labels)\n",
    "        generator_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        if i % 2 == 0:\n",
    "            print(f\"Iteration {i} Epoch {epoch}: D Loss = {discriminator_loss}, G Loss = {generator_loss} \")\n",
    "            \n",
    "        if abs(i-len(trainloader)) <= batch_size:\n",
    "            break          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), \"generator.pth\")\n",
    "torch.save(discriminator.state_dict(), \"discriminator.pth\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate some images\n",
    "with torch.no_grad():\n",
    "    noise_input_test = torch.randn(1, 3, 32,32)   \n",
    "    generated_images = generator(noise_input_test)\n",
    "    image_for_plot = generated_images.squeeze()\n",
    "    image_for_plot = image_for_plot.permute(1, 2, 0)\n",
    "print(image_for_plot.shape)\n",
    "plt.imshow(image_for_plot,cmap='gray')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ea948a86ffb9cb8476bbf8b2af39eb17488da6e229f09db40f40f089fac991a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
